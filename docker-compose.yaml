services:
  briefcast-api:
    image: ghcr.io/d3vv3/whisper-api:latest
    container_name: briefcast-api
    restart: unless-stopped
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - 11000:8000
    volumes:
      - models:/app/models
    environment:
      # tiny.en, tiny, base.en, base, small.en, small, medium.en, medium,
      # large-v1, large-v2, large-v3, large, distil-large-v2,
      # distil-medium.en, distil-small.en
      WHISPER_MODEL: "medium"
      # "auto" or "cuda" or "cpu"
      DEVICE: "cuda"
      # See https://opennmt.net/CTranslate2/quantization.html
      COMPUTE_TYPE: "float16"
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      LOGURU_LEVEL: "INFO"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  models:
