services:
  whisper:
    image: ghcr.io/d3vv3/whisper-api:latest
    container_name: briefcast-whisper
    restart: unless-stopped
    build:
      context: whisper
      dockerfile: Dockerfile
    ports:
      - 11000:8000
    volumes:
      - models:/app/models
    environment:
      # tiny.en, tiny, base.en, base, small.en, small, medium.en, medium,
      # large-v1, large-v2, large-v3, large, distil-large-v2,
      # distil-medium.en, distil-small.en
      WHISPER_MODEL: "small" # "medium"
      # "auto" or "cuda" or "cpu"
      DEVICE: "cpu"  # "cuda"
      # See https://opennmt.net/CTranslate2/quantization.html
      COMPUTE_TYPE: "int8"
      # COMPUTE_TYPE: "float16"
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  trimmer:
    image: ghcr.io/d3vv3/trimmer-api:latest
    build:
      context: trimmer
      dockerfile: Dockerfile
    ports:
      - 11001:80
    environment:
      GEMINI_API_KEY: ${GEMINI_API_KEY}

  chopper:
    image: ghcr.io/d3vv3/chopper-api:latest
    container_name: briefcast-chopper
    restart: unless-stopped
    build:
      context: chopper
      dockerfile: Dockerfile
    ports:
      - 11002:8000

volumes:
  models:
